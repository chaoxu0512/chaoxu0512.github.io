---
layout:     post
title:      理解ResNeXt
subtitle:   
date:       2020-09-22
author:     Chao Xu
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - Image segmentation
---

# 一、介绍

ResNeXt出现于**[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)**，它是一种具有均一性的神经网络，相对于传统的ResNet，ResNeXt减小了超参数的数量。作者在宽度（width）和深度（depth）以外，还提出了一个称为`cardinality`的参数，这个参数的定义是转化（`transformation`）集合的大小。

<p align="center">
  <img src="https://i.loli.net/2020/09/22/wlhsqkvDF8HROZV.png">
    图1
</p>

上图左侧是传统的ResNet block;右侧是ResNeXt block，其cardinality是32。

VGG-nets、ResNet和Inception Networks在特征提取领域已经取得了极大的成就，但他们仍然面对一系列的难题。例如，这些模型可能适用于某些数据集，但是由于它们使用了太多的超参数和计算过程，我们就很难将其直接移植到新的数据集上。

为了克服这些问题，业界已经考虑了结合VGG/ResNet（ResNet是从VGG演变而来的）和Inception Networks的优势。 简而言之，就是将ResNet的重复策略（`repetition strategy`）与Inception Network的拆分-转换-合并策略（`split-transform-merge strategy`）相结合。 换句话说，网络模块将输入分割，将其转换为所需的格式，然后合并以获取输出，每个模块都遵循相同的拓扑（如图1右侧）。

# 二、架构

ResNeXt的基本架构主要遵循两个规则：

1. 如果blocks产生相同维度的空间图，那么它们共享同一组超参数；
2. 如果空间图完全以缩放因子2进行下采样，则blocks的宽度乘以2。

<p align="center">
  <img src="https://i.loli.net/2020/09/22/fGPQUTDmxwjcLph.png">
    图2
</p>

如图2所示，ResNeXt-50的conv2、conv3、conv4和conv5的cardinality均为32。方块内是残差块的形状，方块外是一个conv内堆叠blocks的数量。`C=32`指的是在群卷积（`group convolution`）内有32个群（`group`）。

<p align="center">
  <img src="https://i.loli.net/2020/09/22/p1XaOr3c8vxzHRw.png">
    图3
</p>

- （a）就是前面所见的常规ResNeXt block，其cardinality是32，遵循拆分-转换-合并策略。
- （b）就像从Inception-ResNet中提取的一片叶子。但是，Inception/Inception-ResNet并没有遵循相同的拓扑。
- （c）与AlexNet架构中的群卷积有关。 在（a）和（b）中的32*4就没了，取而代之的是128。在这里，意味着一个群卷积层替代了拆分（splitting）的过程，另一个群卷积层（包含了32个组的卷积）取代了转换（transformation ），最后就是级联了。

在以上3个中，（c）是最好的，因为它易于实现。

# 三、训练和结果

当考虑cardinality而不是宽度/深度时，可以看到ImageNet的准确性有所提高。

<p align="center">
  <img src="https://i.loli.net/2020/09/22/i5YLQkuvMnTNSso.jpg">
    图4
</p>

当cardinality较高时，ResNeXt-50和ResNeXt-101都不太容易出错。 此外，与ResNet相比，ResNeXt表现更良好。

# 四、代码实现

1. [https://pytorch.org/hub/pytorch_vision_resnext/](https://pytorch.org/hub/pytorch_vision_resnext/)

# 五、Reference

[1]. [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)

[2]. [A Review of Popular Deep Learning Architectures: DenseNet, ResNeXt, MnasNet, and ShuffleNet v2](https://blog.paperspace.com/popular-deep-learning-architectures-densenet-mnasnet-shufflen)

[3]. [ResNeXt Block](https://paperswithcode.com/method/resnext-block)

[4]. [Review: ResNeXt — 1st Runner Up in ILSVRC 2016 (Image Classification)](https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac)

[5]. [Understanding and Implementing Architectures of ResNet and ResNeXt for state-of-the-art Image Classification: From Microsoft to Facebook [Part 2]](https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cc5d0adf648e)

[6]. [Enhancing ResNet to ResNeXt for image classification](https://medium.com/dataseries/enhancing-resnet-to-resnext-for-image-classification-3449f62a774c)

